<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width"><link rel=icon type=image/ico href=https://www.tylerhouchin.com//favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://www.tylerhouchin.com//favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://www.tylerhouchin.com//favicon-32x32.png><link rel=icon type=image/png sizes=192x192 href=https://www.tylerhouchin.com//android-chrome-192x192.png><link rel=apple-touch-icon sizes=180x180 href=https://www.tylerhouchin.com//apple-touch-icon.png><link rel=alternate type=application/rss+xml href=https://www.tylerhouchin.com/tags/ai/index.xml title="tyler houchin"><meta name=description content><title>AI | tyler houchin
</title><link rel=canonical href=https://www.tylerhouchin.com/tags/ai/><link rel=stylesheet href=/assets/combined.min.7a7da93198dfce6f15598e04c2ac1fb816c1c43554340ef36fa025ed8f90a119.css media=all><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-T7BDS1PPF2"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-T7BDS1PPF2")}</script></head><body class=auto><div class=content><header><div class=header><h1 class=header-title>tyler houchin</h1><div class=flex><p class=small><a href=/>/home</a></p><p class=small><a href=/blogs>/blogs</a></p></div></div></header><main class=main><div class=list-container><div class=breadcrumbs><a href=/></a><span class=breadcrumbs-separator>> </span><a href=/tags/>Tags</a>
<span class=breadcrumbs-separator>> </span><a class=breadcrumbs-current href=/tags/ai/>AI</a></div><h1>AI</h1><div class=post-line><p class=line-date>01 Dec 2025</p><div><p class=line-title><a href=/blogs/why-is-china-flooding-the-world-with-free-ai/>Why is China Flooding the World with Free AI?</a></p><p class=line-summary><p>Open Twitter on any given day and you&rsquo;re bound to see some new LLM release. However, it seems for every update to GPT/Claude/Gemini, we get 10 updates (or net new releases) from Chinese labs. This began exciting - progress is progress. But it has started to feel eerie. Why is China doing this? Almost all of the improvements made in open source LLMs have been at the hands of the Chinese.</p></p></div></div><div class=post-line><p class=line-date>07 May 2025</p><div><p class=line-title><a href=/blogs/to-rent-or-own-your-ai-brain/>To Rent or Own Your AI Brains</a></p><p class=line-summary><p>Two years ago, when we were still in the prehistoric era of building with LLMs, everyone defaulted to GPT-4. It just worked. An awesome developer experience coupled with a model that is always at the bleeding edge of what&rsquo;s possible is what catalyzed this boom of rapid AI-enabled apps to be developed and shipped.</p><p>Open source models were for those deep in pushing the models to do specific things, but to get the level of intelligence that OpenAI provides via ~2min setup, you needed expensive hardware, time sunk into getting the models running. You couldn&rsquo;t ship nearly as fast. For all of the AI tinkering that I did, if I had to configure spinning up models I would not have explored the problem space of LLMs nearly as much.<figure><div><img loading=lazy alt="2023 Benchmarks" src=/images/blogs/rent-or-own/july_2023_bench.png></div><div class=caption-container><figcaption>July 2023 - Source: <a href=https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/>https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/</a></figcaption></div></figure></p></p></div></div><div class=post-line><p class=line-date>27 Jan 2025</p><div><p class=line-title><a href=/blogs/the-day-ai-got-the-cheapest-again/>The Day AI Got the Cheapest Again</a></p><p class=line-summary><p>Today&rsquo;s market reaction to DeepSeek&rsquo;s <a href=https://github.com/deepseek-ai/DeepSeek-R1>R1 model</a> was dramatic. The Nasdaq dropped 3.1%, and Nvidia saw its stock plummet by 17% - the largest single-day market cap loss in Wall Street history. The narrative? A Chinese hedge fund&rsquo;s ability to train and run powerful AI models at a fraction of the cost threatens the entire AI ecosystem.</p><p><figure><div><img loading=lazy alt="DeepSeek R1 Benchmarks" src=/images/blogs/the-day-ai-got-the-cheapest-again/benchmarks.jpg></div></figure><em>DeepSeek R1&rsquo;s performance benchmarks compared to leading models. AIME tests advanced mathematical reasoning, MATH-500 evaluates complex mathematical problem-solving, GPQA Diamond measures general knowledge and reasoning, LiveCode Bench tests coding ability, and CodeForces rates algorithmic problem-solving skills.</em></p></p></div></div><div class=post-line><p class=line-date>09 Nov 2024</p><div><p class=line-title><a href=/blogs/learn-how-to-learn/>Learn How to Learn</a></p><p class=line-summary><p>In the future, your ability to create software won&rsquo;t be limited by your technical knowledge. It will be limited by how clearly you can think.
Computing started with physical machines - we had to manually arrange circuits and transistors to make anything happen. Then we invented ways to encode instructions using just 1s and 0s. Next came human-readable instructions in assembly language. Then high-level languages like Python that let us write code almost like English. Now we&rsquo;re at LLMs that can turn plain English into working software. Each breakthrough moved us further from thinking like machines and closer to thinking like humans.
But here&rsquo;s what&rsquo;s really interesting: the next abstraction won&rsquo;t be technical at all.</p></p></div></div><div class=post-line><p class=line-date>21 Oct 2024</p><div><p class=line-title><a href=/blogs/maybe-simple-is-all-you-need/>Maybe Simple Is All You Need</a></p><p class=line-summary><p>Enabling self-improvement, where LLMs can autonomously make themselves better, is becoming increasingly feasible in the near future. These language models are already writing prod code (either via copy/paste or Cursor or whoever Devin&rsquo;s clients are), but we’re rapidly heading toward a future where they will also orchestrate entire workflows. This opens the door to the concept of &lsquo;single-use software&rsquo;: when the cost of producing software becomes so cheap that we just write code for everything. The problem isn’t a lack of tasks that could benefit from software, it’s that we lack the resources to develop customized solutions for every use case. Every industry is full of repetitive processes that could be optimized with code, but hiring a dev (or allocating the time of the devs you do have) just isn&rsquo;t worth it. Advanced frameworks like CrewAI and AutoGen are pushing the boundaries of what&rsquo;s possible in multi-agent systems, enabling role delegation, tool use, and task management. <a href=https://www.loom.com/share/cae1aa1bcf4d4a76a2406f1314c23a85>I&rsquo;ve played around with CrewAI</a> and GPT-4o/Claude were pretty good at helping get something running pretty fast, but they weren&rsquo;t zero-shotting it.</p></p></div></div><div class=post-line><p class=line-date>06 Oct 2024</p><div><p class=line-title><a href=/blogs/entering-the-inference-era/>Entering the Inference Era</a></p><p class=line-summary><p>In the world of AI, one of the most transformative insights has been the concept of <strong>scaling laws</strong>—the idea that increasing the amount of compute, data, and model size leads to predictable gains in model intelligence. This principle became evident as AI models like GPT-3 and GPT-4 evolved. For example, GPT-3, with an estimated training cost of $10-20 million, was a massive leap forward in natural language understanding. However, GPT-4, with a training cost of around $100 million, required nearly 40 times more energy and compute than GPT-3. In return, it exhibited significantly improved language comprehension, reasoning, and overall intelligence. This increase in raw compute was a direct factor in the model’s heightened capabilities, demonstrating how scaling laws play out in the realm of model pre-training.</p></p></div></div></div></main></div><footer><p>Powered by
<a href=https://gohugo.io/>Hugo</a>
and
<a href=https://github.com/tomfran/typo>tomfran/typo</a></p></footer></body><script>function isAuto(){return document.body.classList.contains("auto")}function setTheme(){if(!isAuto())return;document.body.classList.remove("auto");let e="light";window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches&&(e="dark"),document.body.classList.add(e)}function invertBody(){document.body.classList.toggle("dark"),document.body.classList.toggle("light")}isAuto()&&window.matchMedia("(prefers-color-scheme: dark)").addListener(invertBody),setTheme()</script></html>