<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>OpenAI on tyler houchin</title><link>https://www.tylerhouchin.com/tags/openai/</link><description>Recent content in OpenAI on tyler houchin</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Wed, 07 May 2025 13:57:10 -0400</lastBuildDate><atom:link href="https://www.tylerhouchin.com/tags/openai/index.xml" rel="self" type="application/rss+xml"/><item><title>To Rent or Own Your AI Brains</title><link>https://www.tylerhouchin.com/blogs/to-rent-or-own-your-ai-brain/</link><pubDate>Wed, 07 May 2025 13:57:10 -0400</pubDate><guid>https://www.tylerhouchin.com/blogs/to-rent-or-own-your-ai-brain/</guid><description>&lt;p>Two years ago, when we were still in the prehistoric era of building with LLMs, everyone defaulted to GPT-4. It just worked. An awesome developer experience coupled with a model that is always at the bleeding edge of what&amp;rsquo;s possible is what catalyzed this boom of rapid AI-enabled apps to be developed and shipped.&lt;/p>
&lt;p>Open source models were for those deep in pushing the models to do specific things, but to get the level of intelligence that OpenAI provides via ~2min setup, you needed expensive hardware, time sunk into getting the models running. You couldn&amp;rsquo;t ship nearly as fast. For all of the AI tinkering that I did, if I had to configure spinning up models I would not have explored the problem space of LLMs nearly as much.











&lt;figure class="">

 &lt;div>
 &lt;img loading="lazy" alt="2023 Benchmarks" src=" /images/blogs/rent-or-own/july_2023_bench.png">
 &lt;/div>

 
 &lt;div class="caption-container">
 &lt;figcaption> July 2023 - Source: &lt;a href="https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/">https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/&lt;/a> &lt;/figcaption>
 &lt;/div>
 
&lt;/figure>&lt;/p></description></item><item><title>The Day AI Got the Cheapest Again</title><link>https://www.tylerhouchin.com/blogs/the-day-ai-got-the-cheapest-again/</link><pubDate>Mon, 27 Jan 2025 00:00:00 +0000</pubDate><guid>https://www.tylerhouchin.com/blogs/the-day-ai-got-the-cheapest-again/</guid><description>&lt;p>Today&amp;rsquo;s market reaction to DeepSeek&amp;rsquo;s &lt;a href="https://github.com/deepseek-ai/DeepSeek-R1">R1 model&lt;/a> was dramatic. The Nasdaq dropped 3.1%, and Nvidia saw its stock plummet by 17% - the largest single-day market cap loss in Wall Street history. The narrative? A Chinese hedge fund&amp;rsquo;s ability to train and run powerful AI models at a fraction of the cost threatens the entire AI ecosystem.&lt;/p>
&lt;p>










&lt;figure class="">

 &lt;div>
 &lt;img loading="lazy" alt="DeepSeek R1 Benchmarks" src=" /images/blogs/the-day-ai-got-the-cheapest-again/benchmarks.jpg">
 &lt;/div>

 
&lt;/figure>
&lt;em>DeepSeek R1&amp;rsquo;s performance benchmarks compared to leading models. AIME tests advanced mathematical reasoning, MATH-500 evaluates complex mathematical problem-solving, GPQA Diamond measures general knowledge and reasoning, LiveCode Bench tests coding ability, and CodeForces rates algorithmic problem-solving skills.&lt;/em>&lt;/p></description></item></channel></rss>