<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>OpenAI on tyler houchin</title>
    <link>http://localhost:1313/tags/openai/</link>
    <description>Recent content in OpenAI on tyler houchin</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 07 May 2025 13:57:10 -0400</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/openai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>To Rent or Own Your AI Brains</title>
      <link>http://localhost:1313/blogs/to-rent-or-own-your-ai-brain/</link>
      <pubDate>Wed, 07 May 2025 13:57:10 -0400</pubDate>
      <guid>http://localhost:1313/blogs/to-rent-or-own-your-ai-brain/</guid>
      <description>&lt;p&gt;Two years ago, when we were still in the prehistoric era of building with LLMs, everyone defaulted to GPT-4. It just works. An awesome developer experience coupled with a model that is always at the bleeding edge of what&amp;rsquo;s possible is what catalyzed this boom of rapid AI-enabled apps to be developed and shipped.&lt;/p&gt;&#xA;&lt;p&gt;Open source models were for those deep in pushing the models to do specific things, but to get the level of intelligence that OpenAI provides via ~2min setup, you needed expensive hardware, time sunk into getting the models running. You couldn&amp;rsquo;t ship nearly as fast. For all of the AI tinkering that I did, if I had to configure spinning up models I would not have explored the problem space of LLMs nearly as much.&lt;/p&gt;</description>
    </item>
    <item>
      <title>The Day AI Got the Cheapest Again</title>
      <link>http://localhost:1313/blogs/the-day-ai-got-the-cheapest-again/</link>
      <pubDate>Mon, 27 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blogs/the-day-ai-got-the-cheapest-again/</guid>
      <description>&lt;p&gt;Today&amp;rsquo;s market reaction to DeepSeek&amp;rsquo;s &lt;a href=&#34;https://github.com/deepseek-ai/DeepSeek-R1&#34;&gt;R1 model&lt;/a&gt; was dramatic. The Nasdaq dropped 3.1%, and Nvidia saw its stock plummet by 17% - the largest single-day market cap loss in Wall Street history. The narrative? A Chinese hedge fund&amp;rsquo;s ability to train and run powerful AI models at a fraction of the cost threatens the entire AI ecosystem.&lt;/p&gt;&#xA;&lt;p&gt;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;&lt;figure class=&#34;&#34;&gt;&#xA;&#xA;    &lt;div&gt;&#xA;        &lt;img loading=&#34;lazy&#34; alt=&#34;DeepSeek R1 Benchmarks&#34; src=&#34; /images/blogs/the-day-ai-got-the-cheapest-again/benchmarks.jpg&#34;&gt;&#xA;    &lt;/div&gt;&#xA;&#xA;    &#xA;&lt;/figure&gt;&#xA;&lt;em&gt;DeepSeek R1&amp;rsquo;s performance benchmarks compared to leading models. AIME tests advanced mathematical reasoning, MATH-500 evaluates complex mathematical problem-solving, GPQA Diamond measures general knowledge and reasoning, LiveCode Bench tests coding ability, and CodeForces rates algorithmic problem-solving skills.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
